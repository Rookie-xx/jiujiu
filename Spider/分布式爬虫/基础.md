### 分布式爬虫介绍

![](C:\Users\my\Desktop\mybook\图片\分布式.png)

+ 原理

```
多台主机共享1个爬取队列
```

+ 实现

```python
重写scrapy调度器(scrapy_redis模块)
```

+ 为什么使用redis

```
1. Redis基于内存，速度快
2. Rdeis非关系型数据库，Redis中集合，存储每个request的指纹
3. scrapy_redis安装
	sudo pip3 install scrapy_redis
```



### scrapy_redis详解

+ #### GitHub地址

```
http://github.com/rmax/scrapy-redis
```

+ #### settings.py说明

```python
#重新指定调度器：启动Redis调度存储请求队列
SCHEDULER = "scrapy_redis.scheduler.Scheduler"

#重新指定去重机制：确保所有的爬虫通过Redis去重
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"

#不清除Redis队列：暂停/恢复/断点续爬
SCHEDULER_PERSIST = Ture

#优先级队列（默认）
SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.PriorityQueue'
#可选用的其他队列
#先进先出队列
SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'
#后进先出队列
SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'

# redis管道
ITEM_PIPELINES = {'scrapy_redis.piplines.RedisPipeline':300}

#指定连接到redis时使用的端口和地址
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
```

