## 1. Utf-8 不能识别 0xb5

>1.查看网页源码，查看网站编码*
>
>  2.decode()第2个参数：ignore,忽略掉特殊字符
>
>```python
> html = res.read().decode('gb2312','ignore')
>```

## 2.多行写入(writerows([(),(),()])) 

newline='' :在Windows中默认会加1行，所以加入newline=''参数

查询20年以前的电影名字和上映时间: select name,tiem from filmtab where time<(now()-interval 20 year);

## 3.解决：urlopen error [SSL: CERTIFICATE_VERIFY_FAILED certificate verify fail

```
import ssl

context = ssl._create_unverified_context()
urllib2.urlopen（'目标网址'，context=context）.read()
```

## 4.requests.get 获取的网页源码编码错误

```python
html = requests.get(url=url,headers=headers)
#如果header中不存在charse，则认为编码为IOS-8859-1


import requests
print('访问baidu网站 获取Response对象')
r = requests.get("http://www.baidu.com")
print(r.status_code)             # 200
print(r.encoding)                # IOS-8859-1
print(r.apparent_encoding)       #从内容中分析响应内容编码方式
print('将对象编码转换成UTF-8编码并打印出来')
r.encoding = 'utf-8'             #编码转成utf-8

```

## 5.爬取百度关键词时出现，百度安全验证，解决方法

```python
#请求头加入 'Accept'

 headers = {
            'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
            'User-Agent':random.choice(ua_list)
                   }
```

## 6.Maximum amount of retries reached

```python
报错代码：
from fake_useragent import UserAgent
>>> ua = UserAgent()
>>> .........
>   fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
    
解决方案：在useragent实例化时加入参数。
from fake_useragent import UserAgent
#正确写法！
ua = UserAgent(verify_ssl=False)    
```

## 7.抛出*SSLError*异常

```python
verify=True(默认)    #检查证书认证
verify=False(常用)   #忽略证书认证

res = requests.get(
verify = False
)
#如果依然报错
pip install -U requests[security]

```

## 8.chromedriver.exe与chrome版本不匹配

```
需要将对应的chromedriver.exe放在C:\Users\my\AppData\Local\Programs\Python\Python37\Scripts  路径下
```

